{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "014de2d4-746d-4143-b9ae-4b19bb7045f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/ajkayode@outlook.com/ehr-project/ehr-project-bundle/envsetup/Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ec98238-8c8d-4df9-9d62-e56c790817bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ProfileBronzeLoad:\n",
    "  def __init__(self):\n",
    "      pass\n",
    "  def make_source_dir(self):\n",
    "    src_dir = (\n",
    "        spark.sql(\n",
    "            f\"\"\"select date_add(last_load_date, 1) as source_dir \n",
    "            from {ats_configs.jobs_metadate_table_name} \n",
    "            where job_name = '{ats_configs.profile_bronze_job_name}'\n",
    "            order by last_load_date desc\n",
    "            \"\"\").first()\n",
    "                .asDict()[\"source_dir\"]\n",
    "                .strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "    return src_dir\n",
    "    \n",
    "  def update_metadata(self, ingestion_date):\n",
    "    print(f\"Updating metadata for {ats_configs.profile_bronze_job_name}\")\n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "        insert into {ats_configs.jobs_metadate_table_name}\n",
    "        values('{ats_configs.profile_bronze_job_name}', \n",
    "            '{ingestion_date}', \n",
    "            current_timestamp(), \n",
    "            'Job Execution Completed.' )\"\"\")\n",
    "    print(f\"Updated metadata for {ats_configs.profile_bronze_job_name}\")\n",
    "  \n",
    "  def load_bronze(self):\n",
    "    print(f\"Loading bronze data for {ats_configs.profile_bronze_job_name}\")\n",
    "    src_dir = self.make_source_dir()\n",
    "    path = f\"/Volumes/{ats_configs.catalog}/{ats_configs.db}/{ats_configs.profile_landing_zone}/{src_dir}\"\n",
    "    df = (\n",
    "        spark.read.format(\"binaryFile\")\n",
    "        .option(\"recursiveFileLookup\", \"true\")\n",
    "        .option(\"maxFilesPerTrigger\", 10)\n",
    "        .option(\"pathGlobFilter\", \"*.pdf\")\n",
    "        .load(f\"{path}\")\n",
    "    )\n",
    "    df.write.mode(\"append\").saveAsTable(ats_configs.profile_bronze_table_name)\n",
    "    self.update_metadata(src_dir)\n",
    "    print(f\"Bronze data load completed for {ats_configs.profile_bronze_table_name}\")\n",
    "\n",
    "  def assert_count(self, table_name, expected_count):\n",
    "      print(f\"Asserting count for {table_name}\")\n",
    "      actual_count = spark.read.table(f\"{ats_configs.catalog}.{ats_configs.db}.{table_name}\").count()\n",
    "      assert (actual_count == expected_count), f\"Expected {expected_count} records in {table_name}, found {actual_count}.\"\n",
    "      print(f\"Asserted count for {table_name}\")\n",
    "\n",
    "  def validate(self, iter):\n",
    "    import time\n",
    "    start = time.time()\n",
    "    print(\"\\nValidating profile load to bronze...\")\n",
    "    for file in iter:\n",
    "      self.assert_count(ats_configs.profile_bronze_table_name, 5 if iter == 1 else 10)\n",
    "    end = time.time()\n",
    "    print(f\"\\nValidated profile bronze load in {end - start} seconds.\")\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29147349-3186-4232-9f90-17bc0b3238ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ProfileBronze = ProfileBronzeLoad()\n",
    "ProfileBronze.load_bronze()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Profile_Source_to_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
