{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fb5dcce-4049-4429-ae92-f3bcae059517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3432e49-bfd2-435e-87c6-e03e3b7c1b01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./model_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d941052-5a09-44dd-8af9-7906fd95e6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./vectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31c1760-668a-4b2f-a49b-53604d5a87b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class envCleanup:\n",
    "  def __init__(self):\n",
    "      pass\n",
    "  def cleanup_metadata(self):\n",
    "      print(\"Deleting Metadata....\", end='')\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jobs_metadate_table_name}\")\n",
    "      print(\"Metadata cleaned up\")\n",
    "\n",
    "  def cleanup_landing_zone(self):\n",
    "      print(\"Deleting landing zone directory....\", end='')\n",
    "      profile_landing_zone = f\"/Volumes/{ats_configs.catalog}/{ats_configs.db}/{ats_configs.profile_landing_zone}\"\n",
    "      dbutils.fs.rm(profile_landing_zone, recurse=True)\n",
    "\n",
    "      jd_landing_zone = f\"/Volumes/{ats_configs.catalog}/{ats_configs.db}/{ats_configs.jd_landing_zone}\"\n",
    "      dbutils.fs.rm(jd_landing_zone, recurse=True)\n",
    "      print(\"Landing zone cleaned up\")\n",
    "\n",
    "  def cleanup_tables(self):\n",
    "      print(\"Deleting tables....\", end='')\n",
    "      spark.sql(f\"drop table if exists {ats_configs.profile_bronze_table_name}\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.profile_silver_table_name}_stg\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.profile_silver_table_name}\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jd_bronze_job_name}\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jd_silver_table_name}_stg\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jd_silver_table_name}\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jd_profile_table_name}_stg\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jd_profile_table_name}\")\n",
    "      spark.sql(f\"drop table if exists {ats_configs.jd_bronze_table_name}\")\n",
    "      print(\"Deleted tables....\", end='')\n",
    "    \n",
    "  def cleanup_endpoints(self):\n",
    "      print(\"Deleting Endpoints....\", end='')\n",
    "      endpoint = Endpoints()\n",
    "      endpoint.delete(ats_configs.chat_model_endpoint_name)\n",
    "      endpoint.delete(ats_configs.embedding_model_endpoint_name)\n",
    "      print(\"Deleted Endpoints....\", end='')\n",
    "      \n",
    "  def vector_index_cleanup(self):\n",
    "      print(\"Deleting Vector Index....\", end='')\n",
    "      import time\n",
    "      vs = VectorSearch()\n",
    "      vs.delete_index(ats_configs.vector_index_name, ats_configs.vector_store_endpoint_name)\n",
    "      time.sleep(20)\n",
    "      print(\"Deleted Vector Index....\", end='')\n",
    "\n",
    "      vs.delete_vector_endpoint(ats_configs.vector_store_endpoint_name)\n",
    "      print(\"Deleted Vector Endpoint....\", end='')\n",
    "\n",
    "  def cleanup_all(self):\n",
    "      self.cleanup_tables()\n",
    "      self.cleanup_endpoints()\n",
    "      self.cleanup_metadata()\n",
    "      self.cleanup_landing_zone()\n",
    "      self.vector_index_cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c4226bc-94c4-4f89-ab5b-82ecba71a1c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleanup = envCleanup()\n",
    "cleanup.cleanup_all()\n",
    "#cleanup.vector_index_cleanup()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "env_cleanup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
